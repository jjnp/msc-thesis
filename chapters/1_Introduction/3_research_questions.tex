\section{Research Questions}

\begin{enumerate}
        \item How can current scaling and placement techniques for load balancers be changed, such that the overall performance of the serverless edge computing system improves?\\\\
    Serverless (edge) computing frameworks typically already possess a mechanism for scaling and placing services. It is also typical for load balancers to be treated as "just another service", and thus identically to functions\cite{openfaas}.
    Conceptually this is not surprising since load balancers, like functions, can be scaled to handle more requests than a single instance could.
    Serverless frameworks do not, however, consider the special role load balancers play in the performance of the system in edge computing scenarios.
    In order to improve the performance, particularly of network bound workloads, the scaling and placement techniques used for load balancers will likely need to be changed. As a result we need to answer the question how the used techniques in that area have to be adapted in order to realize the aspired performance improvements, while still considering the potential side effects this has on the overall system.

        \item How much of a performance improvement can be gained from optimizing the scaling, placement and routing decisions of load balancers in serverless edge computing systems?\\\\
    When investigating what changes could be made in order to increase system responsiveness in serverless edge computing, particularly for network bound workloads, load balancing stands out as an area that is likely to yield significant improvements. Current serverless computing systems do not possess the scaling, placement and load balancing mechanisms required to process requests efficiently in an edge computing scenario. Their implementation is based around the assumptions of relative homogeneity in compute power and network structure one typically finds in cloud computing systems. Even serverless computing frameworks specifically built or adapted for the edge do not necessarily take the heterogeneity of edge computing environments into account. % TODO cite here
    This leaves the question of whether or not adapting serverless edge computing frameworks in regard to the scaling and placement of load balancers, including their routing mechanism, results in performance improvements, and if so, how large they likely are.
    
        \item How do edge optimized scaling and placement techniques for load balancers, including the load balancing techniques themselves, affect the overall system behaviour and characteristics in regard to their key performance metrics?\\\\
    In a serverless computing framework there usually exists an interplay between a number of different components, such as the scaler and the scheduler\cite{openfaas}\cite{kubernetes}. 
    When parts of the system are now changed, in this case the way in which load balancers behave, as well as how they are scaled and placed, this change is potentially liable to affect the rest of the system. Some of these effects would of course be intended, such as better end to end latency, but there could also be additional, potentially unwanted effects. It is thus important how exactly such changes affect the system, and what implications that has. These changes are measured in the form of key performance indicators.
    
\end{enumerate}
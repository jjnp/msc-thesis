
@misc{openfaas-gateway,
  title = {{{OpenFaaS Architecture Documentation}} - {{Gateway}}},
  author = {OpenFaaS Authors},
  note = {Accessed 2021-09-30},
  howpublished = {\url{https://docs.openfaas.com/architecture/gateway/}}
}



@misc{containerd,
  title = {Containerd},
  author = {{containerd Authors}},
  abstract = {An industry-standard container runtime with an emphasis on simplicity, robustness, and portability},
  langid = {american},
  note = {Accessed 2021-09-30},
  howpublished = {\url{https://containerd.io/}}
}



@misc{kubernetes,
  title = {Kubernetes},
  author = {The Kubernetes Authors and The Linux Foundation},
  journal = {Kubernetes},
  abstract = {Production-Grade Container Orchestration},
  langid = {english},
  note = {Accessed 2021-09-30},
  howpublished = {\url{https://kubernetes.io/}}
}



@misc{openwhisk,
  title = {Apache {{OpenWhisk}}},
  author = {The Apache Software Foundation},
  note = {Accessed 2021-09-30},
  howpublished = {\url{https://openwhisk.apache.org/}}
}



@misc{kubeless,
  title = {Kubeless},
  author = {Kubeless},
  note = {Accessed 2021-09-30},
  howpublished = {\url{https://kubeless.io/}}
}



@misc{openfaas,
  title = {{{OpenFaaS}}},
  author = {OpenFaaS Authors},
  abstract = {Serverless Functions Made Simple with Kubernetes.},
  langid = {english},
  note = {Accessed 2021-09-30},
  howpublished = {\url{https://www.openfaas.com/}}
}

@misc{azure-functions,
  title = {Microsoft {{Azure Functions}} - {{Serverless Compute}}},
  author = {Microsoft},
  abstract = {Create event-driven, scalable serverless apps in .NET, Node.js, Python, Java, or PowerShell. Build and debug locally\textemdash deploy and operate at scale in the cloud.},
  langid = {english},
  note = {Accessed 2021-09-30},
  howpublished = {\url{https://azure.microsoft.com/en-us/services/functions/}}
}



@misc{aws-lambda,
  title = {{{AWS Lambda}} \textendash{} {{Serverless Compute}}},
  author = {Amazon Web Services Inc.},
  abstract = {AWS Lambda lets you run code without provisioning or managing servers. You pay only for the compute time you consume.},
  langid = {american},
  note = {Accessed 2021-09-30},
  howpublished = {\url{https://aws.amazon.com/lambda/}}
}


@misc{nginx,
  title = {{{NGINX}}},
  author = {F5 Networks Inc.},
  abstract = {NGINX accelerates content and application delivery, improves security, facilitates availability and scalability for the busiest web sites on the Internet},
  langid = {american},
  note = {Accessed 2021-10-05},
  howpublished = {\url{https://www.nginx.com/}}
}

@misc{nginx-wrr,
  title = {{{NGINX}} - Ngx\_http\_upstream\_round\_robin.c},
  author = {Sysoev, Igor},
  year = {2021},
  month = oct,
  abstract = {An official read-only mirror of http://hg.nginx.org/nginx/ which is updated hourly. Pull requests on GitHub cannot be accepted and will be automatically closed. The proper way to submit changes to nginx is via the nginx development mailing list, see http://nginx.org/en/docs/contributing\_changes.html},
  collaborator = {{Nginx Inc.}},
  note = {Accessed 2021-10-05},
  howpublished = {\url{https://github.com/nginx/nginx/blob/e56ba23158b8466d108fd4d571bd7d9a88f2a473/src/http/ngx_http_upstream_round_robin.c}}
}


@article{osmotic-middleware-rausch,
  title = {Osmotic {{Message}}-{{Oriented Middleware}} for the {{Internet}} of {{Things}}},
  author = {Rausch, Thomas and Dustdar, Schahram and Ranjan, Rajiv},
  year = {2018},
  month = mar,
  journal = {IEEE Cloud Computing},
  volume = {5},
  number = {2},
  pages = {17--25},
  issn = {2325-6095},
  doi = {10.1109/MCC.2018.022171663},
  langid = {english}
}


@inproceedings{rausch-ether,
  title = {Synthesizing {{Plausible Infrastructure Configurations}} for {{Evaluating Edge Computing Systems}}},
  booktitle = {3rd \{\vphantom\}{{USENIX}}\vphantom\{\} {{Workshop}} on {{Hot Topics}} in {{Edge Computing}} ({{HotEdge}} 20)},
  author = {Rausch, Thomas and Lachner, Clemens and Frangoudis, Pantelis A. and Raith, Philipp and Dustdar, Schahram},
  year = {2020},
  langid = {english},
  note = {https://www.usenix.org/conference/hotedge20/presentation/rausch}
}


@misc{faas-sim-github,
  title = {Faas-Sim: A Trace-Driven {{Function}}-as-a-{{Service}} Simulator},
  shorttitle = {Faas-Sim},
  author = {{Thomas Rausch} and {Philipp Raith}},
  year = {2021},
  month = nov,
  abstract = {A framework for trace-driven simulation of serverless Function-as-a-Service platforms},
  copyright = {MIT},
  keywords = {edge-computing,python,serverless-computing,simpy,simulation},
  note = {Accessed 2021-11-11},
  howpublished = {\url{https://github.com/edgerun/faas-sim}}
}



@article{skippy,
  title = {Optimized Container Scheduling for Data-Intensive Serverless Edge Computing},
  author = {Rausch, Thomas and Rashed, Alexander and Dustdar, Schahram},
  year = {2021},
  month = jan,
  journal = {Future Generation Computer Systems},
  volume = {114},
  pages = {259--271},
  issn = {0167739X},
  doi = {10.1016/j.future.2020.07.017},
  abstract = {Operating data-intensive applications on edge systems is challenging, due to the extreme workload and device heterogeneity, as well as the geographic dispersion of compute and storage infrastructure. Serverless computing has emerged as a compelling model to manage the complexity of such systems, by decoupling the underlying infrastructure and scaling mechanisms from applications. Although serverless platforms have reached a high level of maturity, we have found several limiting factors that inhibit their use in an edge setting. This paper presents a container scheduling system that enables such platforms to make efficient use of edge infrastructures. Our scheduler makes heuristic trade-offs between data and computation movement, and considers workload-specific compute requirements such as GPU acceleration. Furthermore, we present a method to automatically fine-tune the weights of scheduling constraints to optimize high-level operational objectives such as minimizing task execution time, uplink usage, or cloud execution cost. We implement a prototype that targets the container orchestration system Kubernetes, and deploy it on an edge testbed we have built. We evaluate our system with trace-driven simulations in different infrastructure scenarios, using traces generated from running representative workloads on our testbed. Our results show that (a) our scheduler significantly improves the quality of task placement compared to the state-of-the-art scheduler of Kubernetes, and (b) our method for fine-tuning scheduling parameters helps significantly in meeting operational goals. \textcopyright{} 2020 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).},
  langid = {english}
}

@phdthesis{philipp-da,
  title = {Container {{Scheduling}} on {{Heterogeneous Clusters}} Using {{Machine Learning}}-Based {{Workload Characterization}}},
  author = {Raith, Philipp Alexander and Rausch, Thomas and {Dustdar, Schahram}},
  year = {2021},
  month = feb,
  address = {{Vienna}},
  langid = {english},
  school = {Vienna University of Technology}
}


@phdthesis{thomas-thesis,
  title = {{A Distributed Compute Fabric for Edge Intelligence}},
  author = {Rausch, Thomas and {Dustdar, Schahram}},
  year = {2021},
  month = may,
  langid = {german},
  school = {Vienna University of Technology}
}


@article{shiEdgeComputingVisionChallenges2016,
  title = {Edge {{Computing}}: Vision and {{Challenges}}},
  shorttitle = {Edge {{Computing}}},
  author = {Shi, Weisong and Cao, Jie and Zhang, Quan and Li, Youhuizi and Xu, Lanyu},
  year = {2016},
  month = oct,
  journal = {IEEE Internet of Things Journal},
  volume = {3},
  number = {5},
  pages = {637--646},
  issn = {2327-4662},
  doi = {10.1109/JIOT.2016.2579198},
  abstract = {The proliferation of Internet of Things (IoT) and the success of rich cloud services have pushed the horizon of a new computing paradigm, edge computing, which calls for processing the data at the edge of the network. Edge computing has the potential to address the concerns of response time requirement, battery life constraint, bandwidth cost saving, as well as data safety and privacy. In this paper, we introduce the definition of edge computing, followed by several case studies, ranging from cloud offloading to smart home and city, as well as collaborative edge to materialize the concept of edge computing. Finally, we present several challenges and opportunities in the field of edge computing, and hope this paper will gain attention from the community and inspire more research in this direction.},
  langid = {english}
}


@misc{telemd-github,
  title = {Telemd},
  author = {{Edgerun Authors}},
  year = {2021},
  month = sep,
  abstract = {Daemon for fine-grained system runtime data monitoring},
  keywords = {go,metrics,monitoring},
  note = {Accessed 2021-11-11},
  howpublished = {\url{https://github.com/edgerun/telemd}}
}


@misc{galileo-github,
  title = {Galileo: A Framework for Distributed Load Testing Experiments},
  shorttitle = {Galileo},
  author = {{Rausch, Thomas} and {Raith, Philipp} and {Palecek, Jacob}},
  year = {2021},
  month = sep,
  abstract = {A framework for distributed load testing experiments},
  keywords = {distributed-load-testing,evaluation-framework,load-testing,python},
  note = {Accessed 2021-11-11},
  howpublished = {\url{https://github.com/edgerun/galileo}}
}


@inproceedings{operating-energy-aware-galileo,
  title = {A System for Operating Energy-Aware Cloudlets: Demo},
  shorttitle = {A System for Operating Energy-Aware Cloudlets},
  booktitle = {Proceedings of the 4th {{ACM}}/{{IEEE Symposium}} on {{Edge Computing}}},
  author = {Rausch, Thomas and Raith, Philipp and Pillai, Padmanabhan and Dustdar, Schahram},
  year = {2019},
  month = nov,
  pages = {307--309},
  publisher = {{ACM}},
  address = {{Arlington Virginia}},
  doi = {10.1145/3318216.3363325},
  abstract = {We present an end-to-end system for operating energy-aware cloudlets with a low-footprint cluster manager and an adaptive client-side load balancing approach. Our system is designed for small-scale high-density compute clusters that host stateless services and have stringent energy resource constraints. It features cluster and service management, runtime monitoring, adaptive load balancing and cluster reconfiguration policies. Furthermore, we present an experimentation and analytics system that allows coordinated execution of complex workload experiments to evaluate different operational strategies.},
  isbn = {978-1-4503-6733-2},
  langid = {english}
}



@misc{traefik,
  title = {Traefik, {{The Cloud Native Application Proxy}}},
  author = {{Traefik Labs}},
  journal = {Traefik Labs: Makes Networking Boring},
  abstract = {Traefik is the leading open-source reverse proxy and load balancer for HTTP and TCP-based applications that is easy, dynamic and full-featured.},
  langid = {english},
  note = {Accessed 2021-11-11},
  howpublished = {\url{https://traefik.io/traefik/}}
}


@misc{traefik-jjnp,
  title = {Jjnp/Traefik},
  author = {{Traefik Labs} and {Palecek, Jacob}},
  year = {2021},
  month = sep,
  abstract = {The Cloud Native Edge Router},
  copyright = {MIT},
  note = {Accessed 2021-11-11},
  howpublished = {\url{https://github.com/jjnp/traefik/tree/load-balancing}}
}


@misc{traefik-dockerhub,
  title = {Traefik | {{Docker Hub}}},
  author = {{Docker Inc.} and {Traefik Labs}},
  note = {Accessed 2021-11-11},
  howpublished = {\url{https://hub.docker.com/_/traefik?tab=tags}}
}


@misc{palecekResponder2021,
  title = {Responder},
  author = {Palecek, Jacob},
  year = {2021},
  month = oct,
  abstract = {Responds to http requests after a set delay. Useful for load testing of network components such as load balancers, and other research topics.},
  copyright = {MIT},
  note = {Accessed 2021-11-11},
  howpublished = {\url{https://github.com/jjnp/responder}}
}


@misc{wrr-kblinux,
  title = {Weighted {{Round}}-{{Robin Scheduling}} - {{LVSKB}}},
  author = {{Linux Virtual Server Authors}},
  note = {Accessed 2021-11-23},
  howpublished = {\url{http://kb.linuxvirtualserver.org/wiki/Weighted_Round-Robin_Scheduling}}
}


@misc{wondernetworkGlobalPingStatistics,
  title = {Global {{Ping Statistics}}},
  author = {{Wonder Network}},
  journal = {WonderNetwork},
  abstract = {WonderNetwork operates a global network of servers and leverages them to provide network testing solutions. View ping times between WonderNetwork servers.},
  note = {Accessed 2021-11-23},
  howpublished = {\url{https://wondernetwork.com/pings}}
}



@inproceedings{beraldiCooperativeLoadBalancing2017,
  title = {Cooperative Load Balancing Scheme for Edge Computing Resources},
  booktitle = {2017 {{Second International Conference}} on {{Fog}} and {{Mobile Edge Computing}} ({{FMEC}})},
  author = {Beraldi, Roberto and Mtibaa, Abderrahmen and Alnuweiri, Hussein},
  year = {2017},
  month = may,
  pages = {94--100},
  publisher = {{IEEE}},
  address = {{Valencia, Spain}},
  doi = {10.1109/FMEC.2017.7946414},
  abstract = {Edge Computing, as a solution to leveraging computation capabilities at the edge of the network, is emerging. One key challenge for edge computing is offering its computing service with a low service blocking and low latency that otherwise translate to an inefficient deployment of a Edge computing system. Unlike cloud computing, the computing resources in edge computing are limited. One way to deal with this limitation is by enabling cooperation between data centers.},
  isbn = {978-1-5386-2859-1},
  langid = {english}
}

@article{gardnerScalableLoadBalancing2021,
  title = {Scalable Load Balancing in the Presence of Heterogeneous Servers},
  author = {Gardner, Kristen and Abdul Jaleel, Jazeem and Wickeham, Alexander and Doroudi, Sherwin},
  year = {2021},
  month = jan,
  journal = {Performance Evaluation},
  volume = {145},
  pages = {102151},
  issn = {01665316},
  doi = {10.1016/j.peva.2020.102151},
  abstract = {Heterogeneity is becoming increasingly ubiquitous in modern large-scale computer systems. Developing good load balancing policies for systems whose resources have varying speeds is crucial in achieving low response times. Indeed, how best to dispatch jobs to servers is a classical and well-studied problem in the queueing literature. Yet the bulk of existing work on large-scale systems assumes homogeneous servers; unfortunately, policies that perform well in the homogeneous setting can cause unacceptably poor performance in heterogeneous systems.},
  langid = {english}
}

@article{karagiannisEdgeRoutingUsingCompute2021,
  title = {{{edgeRouting}}: Using {{Compute Nodes}} in {{Proximity}} to {{Route IoT Data}}},
  shorttitle = {{{edgeRouting}}},
  author = {Karagiannis, Vasileios and Schulte, Stefan},
  year = {2021},
  journal = {IEEE Access},
  volume = {9},
  pages = {105841--105858},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2021.3099942},
  abstract = {Due to the proliferation of edge computing, cloud providers have started offering compute nodes at the edge of the network in addition to traditional compute nodes in data centers. So far, various systems have been proposed for processing Internet of Things (IoT) data on both edge and cloud compute nodes in order to reduce the communication latency. However, such systems do not typically consider that the network bandwidth between an edge node and a cloud node can be orders of magnitude higher than the bandwidth between an IoT device and a cloud node. As a result, the IoT data are commonly sent selectively to either edge or cloud nodes disregarding alternative network paths through edge nodes, which may have higher network bandwidth, and lower communication latency.},
  langid = {english}
}

@inproceedings{kogiasBypassingLoadBalancer2020,
  title = {Bypassing the Load Balancer without Regrets},
  booktitle = {Proceedings of the 11th {{ACM Symposium}} on {{Cloud Computing}}},
  author = {Kogias, Marios and Iyer, Rishabh and Bugnion, Edouard},
  year = {2020},
  month = oct,
  pages = {193--207},
  publisher = {{ACM}},
  address = {{Virtual Event USA}},
  doi = {10.1145/3419111.3421304},
  abstract = {Load balancers are a ubiquitous component of cloud deployments and the cornerstone of workload elasticity. Load balancers can significantly affect the end-to-end application latency with their load balancing decisions, and constitute a significant portion of cloud tenant expenses.},
  isbn = {978-1-4503-8137-6},
  langid = {english}
}

@inproceedings{manjuEfficientLoadBalancing2019,
  title = {Efficient {{Load Balancing Algorithm}} for {{Task Preprocessing}} in {{Fog Computing Environment}}},
  booktitle = {Smart {{Intelligent Computing}} and {{Applications}}},
  author = {Manju, A. B. and Sumathy, S.},
  editor = {Satapathy, Suresh Chandra and Bhateja, Vikrant and Das, Swagatam},
  year = {2019},
  series = {Smart {{Innovation}}, {{Systems}} and {{Technologies}}},
  pages = {291--298},
  publisher = {{Springer}},
  address = {{Singapore}},
  doi = {10.1007/978-981-13-1927-3_31},
  abstract = {Focus and research on fog computing environment is increasing in recent days. Orchestrating the resources in the fog computing environment and distributing the task with the help of simple load balancing algorithms improve the task processing in fog environment. Fog resources include end users resources, networking resources, and cloud resources as well, in which networking resources take the central control over the fog nodes at particular location. These control nodes attempt to reduce the burden of cloud as well as improve the task processing efficiency by distributing the load across the fog nodes evenly on controlling the fog nodes based on availability of the nodes. The objective of this work is to evenly distribute the load across the available fog nodes and reduce the response time of the task processing. The results have been verified using cloud analyst tool in which the proposed approach is compared with round-robin algorithm in terms of response time. The results show that the response time has improved substantially in the proposed approach.},
  isbn = {9789811319273},
  langid = {english},
  keywords = {Cloud resources,Fog computing,Fog nodes,Load balancing,Network resources}
}

@article{talaatLoadBalancingOptimization2020,
  title = {A Load Balancing and Optimization Strategy ({{LBOS}}) Using Reinforcement Learning in Fog Computing Environment},
  author = {Talaat, Fatma M. and Saraya, Mohamed S. and Saleh, Ahmed I. and Ali, Hesham A. and Ali, Shereen H.},
  year = {2020},
  month = nov,
  journal = {Journal of Ambient Intelligence and Humanized Computing},
  volume = {11},
  number = {11},
  pages = {4951--4966},
  issn = {1868-5137, 1868-5145},
  doi = {10.1007/s12652-020-01768-8},
  abstract = {Fog computing (FC) can be considered as a computing paradigm which performs Internet of Things (IoT) applications at the edge of the network. Recently, there is a great growth of data requests and FC which lead to enhance data accessibility and adaptability. However, FC has been exposed to many challenges as load balancing (LB) and adaptation to failure. Many LB strategies have been proposed in cloud computing, but they are still not applied effectively in fog. LB is an important issue to achieve high resource utilization, avoid bottlenecks, avoid overload and low load, and reduce response time. In this paper, a LB and optimization strategy (LBOS) using dynamic resource allocation method based on Reinforcement learning and genetic algorithm is proposed. LBOS monitors the traffic in the network continuously, collects the information about each server load, handles the incoming requests, and distributes them between the available servers equally using dynamic resource allocation method. Hence, it enhances the performance even when it's the peak time. Accordingly, LBOS is simple and efficient in real-time systems in fog computing such as in the case of healthcare system. LBOS is concerned with designing an IoT-Fog based healthcare system. The proposed IoT-Fog system consists of three layers, namely: (1) IoT layer, (2) fog layer, and (3) cloud layer. Finally, the experiments are carried out and the results show that the proposed solution improves the quality-of-service in the cloud/fog computing environment in terms of the allocation cost and reduce the response time. Comparing the LBOS with the state-of-the-art algorithms, it achieved the best load balancing Level (85.71\%). Hence, LBOS is an efficient way to establish the resource utilization and ensure the continuous service.},
  langid = {english}
}

@article{vargaftikLSQLoadBalancing2020,
  title = {{{LSQ}}: Load {{Balancing}} in {{Large}}-{{Scale Heterogeneous Systems With Multiple Dispatchers}}},
  shorttitle = {{{LSQ}}},
  author = {Vargaftik, Shay and Keslassy, Isaac and Orda, Ariel},
  year = {2020},
  month = jun,
  journal = {IEEE/ACM Transactions on Networking},
  volume = {28},
  number = {3},
  pages = {1186--1198},
  issn = {1063-6692, 1558-2566},
  doi = {10.1109/TNET.2020.2980061},
  abstract = {Nowadays, the efficiency and even the feasibility of traditional load-balancing policies are challenged by the rapid growth of cloud infrastructure and the increasing levels of server heterogeneity. In such heterogeneous systems with many loadbalancers, traditional solutions, such as J SQ, incur a prohibitively large communication overhead and detrimental incast effects due to herd behavior. Alternative low-communication policies, such as J SQ(d) and the recently proposed J IQ, are either unstable or provide poor performance. We introduce the Local Shortest Queue (LSQ) family of load balancing algorithms. In these algorithms, each dispatcher maintains its own, local, and possibly outdated view of the server queue lengths, and keeps using J SQ on its local view. A small communication overhead is used infrequently to update this local view. We formally prove that as long as the error in these local estimates of the server queue lengths is bounded in expectation, the entire system is strongly stable. Finally, in simulations, we show how simple and stable LSQ policies exhibit appealing performance and significantly outperform existing low-communication policies, while using an equivalent communication budget. In particular, our simple policies often outperform even J SQ due to their reduction of herd behavior. We further show how, by relying on smart servers (i.e., advanced pull-based communication), we can further improve performance and lower communication overhead.},
  langid = {english}
}

@article{wengOptimalLoadBalancing2020,
  title = {Optimal {{Load Balancing}} with {{Locality Constraints}}},
  author = {Weng, Wentao and Zhou, Xingyu and Srikant, R.},
  year = {2020},
  month = nov,
  journal = {Proceedings of the ACM on Measurement and Analysis of Computing Systems},
  volume = {4},
  number = {3},
  pages = {1--37},
  issn = {2476-1249},
  doi = {10.1145/3428330},
  abstract = {Applications in cloud platforms motivate the study of efficient load balancing under job-server constraints and server heterogeneity. In this paper, we study load balancing on a bipartite graph where left nodes correspond to job types and right nodes correspond to servers, with each edge indicating that a job type can be served by a server. Thus edges represent locality constraints, i.e., an arbitrary job can only be served at servers which contain certain data and/or machine learning (ML) models. Servers in this system can have heterogeneous service rates. In this setting, we investigate the performance of two policies named Join-the-Fastest-of-the-Shortest-Queue (JFSQ) and Join-the-Fastest-of-the-Idle-Queue (JFIQ), which are simple variants of Join-the-Shortest-Queue and Join-the-Idle-Queue, where ties are broken in favor of the fastest servers. Under a "well-connected'' graph condition, we show that JFSQ and JFIQ are asymptotically optimal in the mean response time when the number of servers goes to infinity. In addition to asymptotic optimality, we also obtain upper bounds on the mean response time for finite-size systems. We further show that the well-connectedness condition can be satisfied by a random bipartite graph construction with relatively sparse connectivity.},
  langid = {english}
}

@article{zhangSecureOptimizedLoad2021,
  title = {Secure and {{Optimized Load Balancing}} for {{Multitier IoT}} and {{Edge}}-{{Cloud Computing Systems}}},
  author = {Zhang, Wei-Zhe and Elgendy, Ibrahim A. and Hammad, Mohamed and Iliyasu, Abdullah M. and Du, Xiaojiang and Guizani, Mohsen and {El-Latif}, Ahmed A. Abd},
  year = {2021},
  month = may,
  journal = {IEEE Internet of Things Journal},
  volume = {8},
  number = {10},
  pages = {8119--8132},
  issn = {2327-4662, 2372-2541},
  doi = {10.1109/JIOT.2020.3042433},
  langid = {english}
}

@article{zhangStochasticCongestionGame2021,
  title = {Stochastic {{Congestion Game}} for {{Load Balancing}} in {{Mobile}}-{{Edge Computing}}},
  author = {Zhang, Fenghui and Wang, Michael Mao},
  year = {2021},
  month = jan,
  journal = {IEEE Internet of Things Journal},
  volume = {8},
  number = {2},
  pages = {778--790},
  issn = {2327-4662, 2372-2541},
  doi = {10.1109/JIOT.2020.3008009},
  abstract = {Mobile-edge computing can reduce task execution delay and improve the Quality of Experience (QoE) for the network edge users. However, when there are multiple independent cloudlets in the network with the mobile users offloading tasks randomly, how to maintain the load balancing of the independent cloudlets, how to improve the quality of service and users' QoE are still issues need to be solved. To this end, we study these issues from the perspective of game theory and propose decentralized learning algorithms. First, we turn the cloudlets load-balancing issue into a competition that each user minimizes its task execution time, and then a stochastic congestion game with incomplete information is proposed. Second, based on the existence proof of the Nash equilibria by using potential game theory, we propose a multiuser decentralized learning algorithm to obtain the pure Nash equilibrium strategy of each user. Then, an ordinary differential equation is derived to prove the convergence of the algorithm. Finally, we propose two application scenarios, one is for static users and the other is for dynamic users, and then the performances of the algorithm in a static scenario is tested. In order to adapt to dynamic scenarios, and further improve the performance and reduce communication costs, we propose a decentralized learning algorithm with termination condition. The experiments show that this algorithm can improve the load balancing of the multicloudlet system, and enhance the quality of service.},
  langid = {english}
}





